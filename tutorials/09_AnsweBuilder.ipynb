{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `AnswerBuilder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On its own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.builders import AnswerBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = AnswerBuilder(pattern=\"Answer: (.*)\")\n",
    "res = builder.run(query=\"What's the answer?\", replies=[\"This is an argument. Answer: This is the answer.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answers': [GeneratedAnswer(data='This is the answer.', query=\"What's the answer?\", documents=[], meta={})]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.retrievers.in_memory import InMemoryBM25Retriever\n",
    "from haystack_integrations.components.generators.ollama import OllamaGenerator\n",
    "from haystack.components.builders.answer_builder import AnswerBuilder\n",
    "from haystack.components.builders.prompt_builder import PromptBuilder\n",
    "from haystack.utils import Secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "    Given these documents, answer the question.\\nDocuments:\n",
    "    {% for doc in documents %}\n",
    "        {{ doc.content }}\n",
    "    {% endfor %}\n",
    "\n",
    "    \\nQuestion: {{query}}\n",
    "    \\nAnswer:\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Pipeline()\n",
    "p.add_component(instance=InMemoryBM25Retriever(document_store=InMemoryDocumentStore()), name=\"retriever\")\n",
    "p.add_component(instance=PromptBuilder(template=prompt_template), name=\"prompt_builder\")\n",
    "p.add_component(instance=OllamaGenerator(\n",
    "    model=\"zephyr\",\n",
    "    streaming_callback=lambda chunk: print(chunk.content, end=\"\", flush=True),\n",
    "    url = \"http://localhost:11434\",\n",
    "    generation_kwargs={\n",
    "        \"num_predict\": 100,\n",
    "        \"temperature\": 0.9}), name=\"llm\")\n",
    "p.add_component(instance=AnswerBuilder(), name=\"answer_builder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7f4124116ab0>\n",
       "üöÖ Components\n",
       "  - retriever: InMemoryBM25Retriever\n",
       "  - prompt_builder: PromptBuilder\n",
       "  - llm: OllamaGenerator\n",
       "  - answer_builder: AnswerBuilder\n",
       "üõ§Ô∏è Connections\n",
       "  - retriever.documents -> prompt_builder.documents (List[Document])\n",
       "  - retriever.documents -> answer_builder.documents (List[Document])\n",
       "  - prompt_builder.prompt -> llm.prompt (str)\n",
       "  - llm.replies -> answer_builder.replies (List[str])\n",
       "  - llm.meta -> answer_builder.meta (List[Dict[str, Any]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "p.connect(\"prompt_builder\", \"llm\")\n",
    "p.connect(\"llm.replies\", \"answer_builder.replies\")\n",
    "p.connect(\"llm.meta\", \"answer_builder.meta\")\n",
    "p.connect(\"retriever\", \"answer_builder.documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H√† N·ªôi l√† th·ªß ƒë√¥ c·ªßa Vi·ªát Nam. (ƒê∆∞·ª£c bi·∫øt t·ª´ vƒÉn b·∫£n trang th·ª© hai)\n",
      "\n",
      "\n",
      "Explanation:\n",
      "The second document provides the answer to the question. It states that H√† N·ªôi is the capital of Vietnam. Therefore, the answer to the question is H√† N·ªôi."
     ]
    }
   ],
   "source": [
    "query = \"Th·ªß ƒë√¥ c·ªßa Vi·ªát Nam l√† g√¨?\"\n",
    "result = p.run(\n",
    "    {\n",
    "        \"retriever\": {\"query\": query},\n",
    "        \"prompt_builder\": {\"query\": query},\n",
    "        \"answer_builder\": {\"query\": query},\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kubernetes (k8s) l√† m·ªôt ph·∫ßn m·ªÅm open-source d·ª±a tr√™n Go-language, do Google ph√°t tri·ªÉn v√† ph√¢n b·ªï t·ªõi c·ªông ƒë·ªìng m√£ ngu·ªìn m·ªü. N√≥ cho ph√©p qu·∫£n l√Ω v√† t·ª± ƒë·ªông h√≥a quy·∫øt chi·∫øn ch·∫•p thu·∫≠n s·ª≠ d·ª•"
     ]
    }
   ],
   "source": [
    "query = \"Kubernetes l√† g√¨?\"\n",
    "result = p.run(\n",
    "    {\n",
    "        \"retriever\": {\"query\": query},\n",
    "        \"prompt_builder\": {\"query\": query},\n",
    "        \"answer_builder\": {\"query\": query},\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T√¥i bi·∫øt c√°c ng√¥n ng·ªØ m√† d√≤ng m√°y bay Zephyr c√≥ th·ªÉ h·ªó tr·ª£ l√†:\n",
      "- Ti·∫øng Anh (English)\n",
      "- Ti·∫øng Ph√°p (French)\n",
      "- Ti·∫øng ƒê·ª©c (German)\n",
      "- Ti·∫øng T·∫≠p Th·∫≠n (Italian)\n",
      "- Ti·∫øng Nh·∫≠t (Japanese)\n"
     ]
    }
   ],
   "source": [
    "query = \"Cho t√¥i bi·∫øt c√°c ng√¥n ng·ªØ m√† Zephyr model c√≥ th·ªÉ h·ªó tr·ª£\"\n",
    "result = p.run(\n",
    "    {\n",
    "        \"retriever\": {\"query\": query},\n",
    "        \"prompt_builder\": {\"query\": query},\n",
    "        \"answer_builder\": {\"query\": query},\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
