{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `VKS document with llama3`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On its own\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.converters import PDFMinerToDocument\n",
    "from haystack.components.preprocessors import DocumentCleaner\n",
    "from haystack.components.preprocessors import DocumentSplitter\n",
    "from haystack.components.writers import DocumentWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x770e61fa7ec0>\n",
       "🚅 Components\n",
       "  - converter: PDFMinerToDocument\n",
       "  - cleaner: DocumentCleaner\n",
       "  - splitter: DocumentSplitter\n",
       "  - writer: DocumentWriter\n",
       "🛤️ Connections\n",
       "  - converter.documents -> cleaner.documents (List[Document])\n",
       "  - cleaner.documents -> splitter.documents (List[Document])\n",
       "  - splitter.documents -> writer.documents (List[Document])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_document_store = InMemoryDocumentStore()\n",
    "\n",
    "pipeline = Pipeline()\n",
    "pipeline.add_component(\"converter\", PDFMinerToDocument())\n",
    "pipeline.add_component(\"cleaner\", DocumentCleaner())\n",
    "pipeline.add_component(\"splitter\", DocumentSplitter(split_by=\"sentence\", split_length=5))\n",
    "pipeline.add_component(\"writer\", DocumentWriter(document_store=raw_document_store))\n",
    "\n",
    "pipeline.connect(\"converter\", \"cleaner\")\n",
    "pipeline.connect(\"cleaner\", \"splitter\")\n",
    "pipeline.connect(\"splitter\", \"writer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'writer': {'documents_written': 690}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names = [\"sample.pdf\"]\n",
    "pipeline.run({\"converter\": {\"sources\": file_names}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store = InMemoryDocumentStore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initalize a Document Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embedder = SentenceTransformersDocumentEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "doc_embedder.warm_up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24af35e5f1b14a9ea8cea9b5048f5506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "690"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_with_embeddings = doc_embedder.run(raw_document_store.filter_documents())\n",
    "document_store.write_documents(docs_with_embeddings[\"documents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.components.builders import ChatPromptBuilder\n",
    "from haystack.dataclasses import ChatMessage\n",
    "from haystack_integrations.components.generators.ollama import OllamaChatGenerator\n",
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embedder = SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = [ChatMessage.from_user(\"\"\"\n",
    "Given the following information, answer the question.\n",
    "\n",
    "Context:\n",
    "{% for document in documents %}\n",
    "    {{ document.content }}\n",
    "{% endfor %}\n",
    "\n",
    "Question: {{question}}\n",
    "Answer:\n",
    "\"\"\")]\n",
    "\n",
    "prompt_builder = ChatPromptBuilder(template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_generator = OllamaChatGenerator(\n",
    "    model=\"llama3.1:8b\",\n",
    "    streaming_callback=lambda chunk: print(chunk.content, end=\"\", flush=True),\n",
    "    url = \"http://localhost:11434\",\n",
    "    generation_kwargs={\n",
    "        \"num_predict\": 100,\n",
    "        \"temperature\": 0.9})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = InMemoryEmbeddingRetriever(document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_rag_pipeline = Pipeline()\n",
    "# Add components to your pipeline\n",
    "basic_rag_pipeline.add_component(\"text_embedder\", text_embedder)\n",
    "basic_rag_pipeline.add_component(\"retriever\", retriever)\n",
    "basic_rag_pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
    "basic_rag_pipeline.add_component(\"llm\", chat_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x770df219f530>\n",
       "🚅 Components\n",
       "  - text_embedder: SentenceTransformersTextEmbedder\n",
       "  - retriever: InMemoryEmbeddingRetriever\n",
       "  - prompt_builder: ChatPromptBuilder\n",
       "  - llm: OllamaChatGenerator\n",
       "🛤️ Connections\n",
       "  - text_embedder.embedding -> retriever.query_embedding (List[float])\n",
       "  - retriever.documents -> prompt_builder.documents (List[Document])\n",
       "  - prompt_builder.prompt -> llm.messages (List[ChatMessage])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, connect the components to each other\n",
    "basic_rag_pipeline.connect(\"text_embedder.embedding\", \"retriever.query_embedding\")\n",
    "basic_rag_pipeline.connect(\"retriever\", \"prompt_builder\")\n",
    "basic_rag_pipeline.connect(\"prompt_builder.prompt\", \"llm.messages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asking question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3980220e301f487aa93cf286d842aedb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VKS (VNGCloud Kubernetes Service) is a managed service on VNGCloud that helps simplify the deployment and management of container-based applications.VKS (VNGCloud Kubernetes Service) is a managed service on VNGCloud that helps simplify the deployment and management of container-based applications.\n"
     ]
    }
   ],
   "source": [
    "question = \"What is VKS?\"\n",
    "\n",
    "response = basic_rag_pipeline.run({\"text_embedder\": {\"text\": question}, \"prompt_builder\": {\"question\": question}})\n",
    "\n",
    "print(response[\"llm\"][\"replies\"][0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa1524ffd084ff79afe9e78ba32f36f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's the comparison between VKS Private Clusters and VKS Public Clusters based on the provided context:\n",
      "\n",
      "**VKS Private Cluster:**\n",
      "\n",
      "* Ideal for services that require strict access control, ensuring compliance with security regulations and data privacy.\n",
      "* All connections are completely private:\n",
      "\t+ Between nodes to the control plane\n",
      "\t+ From client to the control plane\n",
      "\t+ From nodes to other products and services in VNG Cloud (e.g., vStorage, vCR, vMonitor, VHere's the comparison between VKS Private Clusters and VKS Public Clusters based on the provided context:\n",
      "\n",
      "**VKS Private Cluster:**\n",
      "\n",
      "* Ideal for services that require strict access control, ensuring compliance with security regulations and data privacy.\n",
      "* All connections are completely private:\n",
      "\t+ Between nodes to the control plane\n",
      "\t+ From client to the control plane\n",
      "\t+ From nodes to other products and services in VNG Cloud (e.g., vStorage, vCR, vMonitor, V\n"
     ]
    }
   ],
   "source": [
    "question = \"Compare VKS private clusters and VKS public clusters\"\n",
    "\n",
    "response = basic_rag_pipeline.run({\"text_embedder\": {\"text\": question}, \"prompt_builder\": {\"question\": question}})\n",
    "\n",
    "print(response[\"llm\"][\"replies\"][0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
